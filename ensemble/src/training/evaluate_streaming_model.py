"""
ä¸“é—¨çš„æ¨¡å‹è¯„ä¼°å’Œå¯¹æ¯”è„šæœ¬
"""
import time
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent  # å›åˆ°é¡¹ç›®æ ¹ç›®å½•
sys.path.append(str(project_root))

import torch
import numpy as np
import plotly.graph_objects as go
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report
from tqdm import tqdm

from ensemble.src.training.streaming_multi_rocket import StreamingMultiRocketClassifier, StreamingInferenceEngine
from ensemble.src.training.data_loader import TrajectoryDataLoader


def load_trained_model(checkpoint_path: str, device: str = 'auto'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    if device == 'auto':
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    elif device == 'cpu':
        device = torch.device("cpu")
    elif device == 'cuda':
        device = torch.device("cuda")
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è®¾å¤‡: {device}")
    
    print(f"ä» {checkpoint_path} åŠ è½½æ¨¡å‹...")
    
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
    
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    
    # é‡å»ºæ¨¡å‹
    data_info = checkpoint['data_info']
    config = checkpoint.get('config')
    
    model = StreamingMultiRocketClassifier(
        c_in=data_info['num_features'],
        c_out=data_info['num_classes'],
        max_seq_len=data_info['seq_len'],
        num_features=getattr(config, 'num_features', 10_000),
        dropout=getattr(config, 'dropout', 0.2),
        # confidence_threshold=getattr(config, 'confidence_threshold', 0.9)
        confidence_threshold=1.0
    ).to(device)
    
    # åŠ è½½æƒé‡
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   æ”¯æŒçš„åºåˆ—é•¿åº¦: {model.supported_lengths}")
    print(f"   æ•°æ®ä¿¡æ¯: {data_info}")
    
    return model, checkpoint, device


def evaluate_streaming(model, data_loader, device, detailed_analysis=True):
    """å¯¹æ¯”æµå¼æ¨ç†å’Œæ‰¹é‡æ¨ç†çš„æ€§èƒ½"""
    print("=" * 50)
    
    model.eval()
    
    # å­˜å‚¨ç»“æœ
    streaming_results = {
        'predictions': [],
        'labels': [],
        'begin_time': [],
        'rates': [],
        'stop_timesteps': [],
        'inference_times': [],
        'timestep_predictions': []  # æ¯ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹å†å²
    }
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(tqdm(data_loader, desc="è¯„ä¼°ä¸­")):
            sequences = batch['sequences'].to(device)  # (batch, seq_len, features)
            labels = batch['labels'].to(device)
            
            # æµå¼æ¨ç†
            for i in range(sequences.shape[0]):
                seq = sequences[i].cpu().numpy()  # (seq_len, features)
                true_label = labels[i].item()
                
                engine = StreamingInferenceEngine(model)
                
                start_time = time.time()
                timestep_preds = []

                # é€æ­¥æ·»åŠ æ—¶é—´æ­¥
                is_begin = False
                for t in range(len(seq)):
                    features = seq[t]
                    result = engine.add_timestep(features)

                    prediction = result['prediction']
                    timestep_preds.append(prediction)

                    if true_label == prediction and not is_begin:
                        is_begin = True
                        streaming_results['begin_time'].append(t + 1)

                if not is_begin:
                    streaming_results['begin_time'].append(len(seq))
                streaming_time = time.time() - start_time

                result = engine.get_final_prediction()
                final_pred = result['prediction']
                stop_step = result['stop_timestep']
                rate = result['rate']

                streaming_results['predictions'].append(final_pred)
                streaming_results['labels'].append(true_label)
                streaming_results['rates'].append(rate)
                streaming_results['stop_timesteps'].append(stop_step)
                streaming_results['inference_times'].append(streaming_time)
                streaming_results['timestep_predictions'].append(timestep_preds)
            

    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    streaming_accuracies = []
    predictions = np.array(streaming_results['predictions'])
    labels = np.array(streaming_results['labels'])
    rates = np.array(streaming_results['rates'])
    timestep_predictions = np.array(streaming_results['timestep_predictions'])
    for t in range(sequences.shape[0]):
        pred_t = timestep_predictions[:, t]
        streaming_accuracies.append(accuracy_score(labels, pred_t))
    avg_acc = 0
    for i in range(len(labels)):
        if predictions[i] == labels[i] and rates[i] >= 0.9:
            avg_acc += 1
    avg_acc /= len(labels)

    streaming_prec, streaming_rec, streaming_f1, _ = precision_recall_fscore_support(
        labels, predictions, average='weighted'
    )
    
    # æ—¶é—´ç»Ÿè®¡
    avg_streaming_time = np.mean(streaming_results['inference_times']) * 1000  # ms
    
    # æ—©æœŸåœæ­¢ç»Ÿè®¡
    avg_stop_timestep = np.mean(streaming_results['stop_timesteps'])
    avg_begin_timestep = np.mean(streaming_results['begin_time'])
    max_timesteps = max(streaming_results['stop_timesteps'])
    
    print(f"{'æŒ‡æ ‡':<20} {'æµå¼æ¨ç†':<15}")
    print("-" * 65)
    print(f"{'å‡†ç¡®ç‡':<20} {avg_acc:<15.4f}")
    print(f"{'ç²¾ç¡®ç‡':<20} {streaming_prec:<15.4f}")
    print(f"{'å¬å›ç‡':<20} {streaming_rec:<15.4f}")
    print(f"{'F1åˆ†æ•°':<20} {streaming_f1:<15.4f}")
    print(f"{'æ¨ç†æ—¶é—´(ms)':<20} {avg_streaming_time:<15.2f}")
    print(f"{'å¹³å‡å¼€å§‹æ—¶é—´æ­¥':<20} {avg_begin_timestep:.1f}")
    print(f"{'å¹³å‡åœæ­¢æ—¶é—´æ­¥':<20} {avg_stop_timestep:.1f} / {max_timesteps}")

    if detailed_analysis:
        # è¯¦ç»†åˆ†æ
        fig = go.Figure(data=[
            go.Scatter(x=np.arange(1, len(streaming_accuracies)+1), y=streaming_accuracies, mode='lines')
        ])
        fig.update_layout(
            title="å‡†ç¡®ç‡éšæ—¶é—´æ­¥å˜åŒ–",
            xaxis_title="æ—¶é—´æ­¥",
            yaxis_title="å‡†ç¡®ç‡",
            legend_title="å‡†ç¡®ç‡"
        )
        fig.show()

    return {
        'streaming_results': streaming_results,
        'metrics': {
            'streaming_accuracy': streaming_prec,
            'avg_stop_timestep': avg_stop_timestep,
        }
    }


def comprehensive_model_evaluation(checkpoint_path: str):
    """ç»¼åˆæ¨¡å‹è¯„ä¼°"""
    print("ğŸ” ç»¼åˆæ¨¡å‹è¯„ä¼°")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    device = 'auto'
    model, checkpoint, device = load_trained_model(checkpoint_path, device)
    
    # åŠ è½½æ•°æ®
    print("\\nåŠ è½½æµ‹è¯•æ•°æ®...")
    data_loader = TrajectoryDataLoader(
        batch_size=64,
        train_split=0.7,
        val_split=0.15,
        test_split=0.15,
        shuffle=False,
        num_workers=4,
        pretrained_scaler=os.path.join(os.path.dirname(checkpoint_path), 'data_scaler.pth'),
        random_state=42,
    )

    _, _, test_loader = data_loader.get_dataloaders()
    
    # è¿›è¡Œç»¼åˆè¯„ä¼°
    evaluation_results = evaluate_streaming(model, test_loader, device, detailed_analysis=False)
    
    return evaluation_results


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æµå¼MultiRocketæ¨¡å‹è¯„ä¼°ç³»ç»Ÿ")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶
    checkpoint_path = "checkpoints/best_streaming_model.pth"

    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹")
        return
    
    comprehensive_model_evaluation(checkpoint_path)


if __name__ == "__main__":
    main()