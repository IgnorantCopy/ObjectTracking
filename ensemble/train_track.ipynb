{
 "cells": [
  {
   "cell_type": "code",
   "id": "dee6052d21fde066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T16:13:06.357242Z",
     "start_time": "2025-07-28T16:13:04.342203Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from data.track_preprocess import TrajectoryDataProcessor, process_df"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T16:13:06.489850Z",
     "start_time": "2025-07-28T16:13:06.486952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_ROOT = r'D:\\DataSets\\挑战杯_揭榜挂帅_CQ-08赛题_数据集'\n",
    "NUM_CLASSES = 4\n",
    "SEQ_LEN = 12"
   ],
   "id": "fa27666413251e36",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T16:13:06.514647Z",
     "start_time": "2025-07-28T16:13:06.506709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data(data_root: str, num_classes: int, time: int):\n",
    "    if time > SEQ_LEN:\n",
    "        raise ValueError(f\"time {time} should be less than or equal to SEQ_LEN {SEQ_LEN}\")\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    point_files = glob.glob(os.path.join(data_root, '点迹/PointTracks_*.txt'))\n",
    "    for point_file in point_files:\n",
    "        match_result = re.match(r'PointTracks_(\\d+)_(\\d+)_(\\d+).txt', os.path.basename(point_file))\n",
    "        batch_id = int(match_result.group(1))\n",
    "        label = int(match_result.group(2))\n",
    "        num_tracks = int(match_result.group(3))\n",
    "        if label > num_classes:\n",
    "            continue\n",
    "        track_file = os.path.join(data_root, f\"航迹/Tracks_{batch_id}_{label}_{num_tracks}.txt\")\n",
    "\n",
    "        preprocessed_data = TrajectoryDataProcessor(point_file, track_file).get_processed_data()\n",
    "        point_df = pl.from_pandas(preprocessed_data['point_data'])\n",
    "        track_df = pl.from_pandas(preprocessed_data['track_data'])\n",
    "        df = point_df.join(track_df, on=[\"时间\", \"批号\"], how=\"left\").sort(\"时间\")\n",
    "        df = process_df(df)\n",
    "        data_batch = df.to_numpy(order='c').astype(np.float32)\n",
    "        data_batch = data_batch[:time, :]\n",
    "        data.append(data_batch)\n",
    "        labels.append(label - 1)\n",
    "    data = np.concatenate(data, axis=0)\n",
    "    labels = np.array(labels)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    # normalize\n",
    "    train_scaler = StandardScaler()\n",
    "    train_data = train_scaler.fit_transform(train_data)\n",
    "    test_scaler = StandardScaler()\n",
    "    test_data = test_scaler.fit_transform(test_data)\n",
    "    return train_data, test_data, train_labels, test_labels, train_scaler, test_scaler"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T16:13:09.067606Z",
     "start_time": "2025-07-28T16:13:06.524697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for t in range(1, SEQ_LEN + 1):\n",
    "    train_data, test_data, train_labels, test_labels, train_scaler, test_scaler = get_data(DATA_ROOT, NUM_CLASSES, t)\n",
    "    knn_tsc = KNeighborsTimeSeriesClassifier(n_neighbors=3)\n",
    "    knn_tsc.fit(train_data, train_labels)\n",
    "    pred_labels = knn_tsc.predict(test_data)\n",
    "    acc = accuracy_score(test_labels, pred_labels)\n",
    "    print(f\"time {t}, acc: {acc}\")"
   ],
   "id": "62d8f088fbed09da",
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "平均全速度",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mColumnNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m, SEQ_LEN + \u001B[32m1\u001B[39m):\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     train_data, test_data, train_labels, test_labels, train_scaler, test_scaler = get_data(DATA_ROOT, NUM_CLASSES, t)\n\u001B[32m      3\u001B[39m     knn_tsc = KNeighborsTimeSeriesClassifier(n_neighbors=\u001B[32m3\u001B[39m)\n\u001B[32m      4\u001B[39m     knn_tsc.fit(train_data, train_labels)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 21\u001B[39m, in \u001B[36mget_data\u001B[39m\u001B[34m(data_root, num_classes, time)\u001B[39m\n\u001B[32m     19\u001B[39m track_df = pl.from_pandas(preprocessed_data[\u001B[33m'\u001B[39m\u001B[33mtrack_data\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m     20\u001B[39m df = point_df.join(track_df, on=[\u001B[33m\"\u001B[39m\u001B[33m时间\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m批号\u001B[39m\u001B[33m\"\u001B[39m], how=\u001B[33m\"\u001B[39m\u001B[33mleft\u001B[39m\u001B[33m\"\u001B[39m).sort(\u001B[33m\"\u001B[39m\u001B[33m时间\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m df = process_df(df)\n\u001B[32m     22\u001B[39m data_batch = df.to_numpy(order=\u001B[33m'\u001B[39m\u001B[33mc\u001B[39m\u001B[33m'\u001B[39m).astype(np.float32)\n\u001B[32m     23\u001B[39m data_batch = data_batch[:time, :]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\codespace\\codes\\ObjectTracking\\ensemble\\data\\track_preprocess.py:105\u001B[39m, in \u001B[36mprocess_df\u001B[39m\u001B[34m(df)\u001B[39m\n\u001B[32m     90\u001B[39m \u001B[38;5;66;03m# 最终的特征\u001B[39;00m\n\u001B[32m     91\u001B[39m final_feature_columns = [\n\u001B[32m     92\u001B[39m     \u001B[38;5;66;03m# 衍生特征\u001B[39;00m\n\u001B[32m     93\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m高度\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m水平速度\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m爬升/俯冲角度_弧度\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mRCS\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    103\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m俯仰\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m多普勒速度\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m和幅度\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m信噪比\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m原始点数量\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    104\u001B[39m ]\n\u001B[32m--> \u001B[39m\u001B[32m105\u001B[39m df_final_features = df.select(final_feature_columns)\n\u001B[32m    106\u001B[39m \u001B[38;5;66;03m# 填充所有因计算差分等产生的空值\u001B[39;00m\n\u001B[32m    107\u001B[39m df_final_features = df_final_features.fill_null(\u001B[32m0.0\u001B[39m).fill_nan(\u001B[32m0.0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\ObjectTracking\\Lib\\site-packages\\polars\\dataframe\\frame.py:9833\u001B[39m, in \u001B[36mDataFrame.select\u001B[39m\u001B[34m(self, *exprs, **named_exprs)\u001B[39m\n\u001B[32m   9731\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   9732\u001B[39m \u001B[33;03mSelect columns from this DataFrame.\u001B[39;00m\n\u001B[32m   9733\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   9826\u001B[39m \u001B[33;03m└──────────────┘\u001B[39;00m\n\u001B[32m   9827\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   9828\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpolars\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlazyframe\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mopt_flags\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m QueryOptFlags\n\u001B[32m   9830\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[32m   9831\u001B[39m     \u001B[38;5;28mself\u001B[39m.lazy()\n\u001B[32m   9832\u001B[39m     .select(*exprs, **named_exprs)\n\u001B[32m-> \u001B[39m\u001B[32m9833\u001B[39m     .collect(optimizations=QueryOptFlags._eager())\n\u001B[32m   9834\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\ObjectTracking\\Lib\\site-packages\\polars\\_utils\\deprecation.py:97\u001B[39m, in \u001B[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     93\u001B[39m         kwargs[\u001B[33m\"\u001B[39m\u001B[33mengine\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33min-memory\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m kwargs[\u001B[33m\"\u001B[39m\u001B[33mstreaming\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m97\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m function(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\ObjectTracking\\Lib\\site-packages\\polars\\lazyframe\\opt_flags.py:330\u001B[39m, in \u001B[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m         optflags = cb(optflags, kwargs.pop(key))  \u001B[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001B[39;00m\n\u001B[32m    329\u001B[39m kwargs[\u001B[33m\"\u001B[39m\u001B[33moptimizations\u001B[39m\u001B[33m\"\u001B[39m] = optflags\n\u001B[32m--> \u001B[39m\u001B[32m330\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m function(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\ObjectTracking\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2332\u001B[39m, in \u001B[36mLazyFrame.collect\u001B[39m\u001B[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001B[39m\n\u001B[32m   2330\u001B[39m \u001B[38;5;66;03m# Only for testing purposes\u001B[39;00m\n\u001B[32m   2331\u001B[39m callback = _kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mpost_opt_callback\u001B[39m\u001B[33m\"\u001B[39m, callback)\n\u001B[32m-> \u001B[39m\u001B[32m2332\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m wrap_df(ldf.collect(engine, callback))\n",
      "\u001B[31mColumnNotFoundError\u001B[39m: 平均全速度"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
